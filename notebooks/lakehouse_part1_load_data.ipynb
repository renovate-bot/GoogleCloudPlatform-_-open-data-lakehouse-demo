{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Hbol",
      "metadata": {
        "id": "Hbol"
      },
      "source": [
        "# Ridership Open Lakehouse Demo\n",
        "\n",
        "This notebook will demonstrate a strategy to implement an open lakehouse on GCP, using Apache Iceberg,\n",
        "as an open source standard for managing data, while still leveraging GCP native capabilities. This demo will use\n",
        "BigQuery Manged Iceberg Tables, Managed Apache Kafka and Apache Kafka Connect to ingest streaming data, Vertex AI for Generative AI queries on top of the data and Dataplex to govern tables.\n",
        "\n",
        "This notebook will load data into BigQuery, backed by Parquet files, in the Apache Iceberg specification.\n",
        "\n",
        "After loading, we will demonstrate processing the data using PySpark.\n",
        "\n",
        "The processing will simulate `bus ridership` data, based on `bus station ridership` data. The `bus station ridership` shows passangers waiting at a given station at a given timestamp. Our PySpark processing pipelines will create a time windows, simulating a bus picking up those passangers while driving it's route. The routes for the buses are taken from the pre-made `bus_lines` table.\n",
        "\n",
        "All data in this notebook was prepared in the previous `part0` notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MJUe",
      "metadata": {
        "marimo": {
          "config": {
            "hide_code": true
          }
        },
        "id": "MJUe"
      },
      "source": [
        "## Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "vblA",
      "metadata": {
        "id": "vblA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8451fe24-e8c7-45e1-e77b-2f05b82af43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lakehouse-demo-1000\n",
            "lakehouse-demo-1000-ridership-lakehouse\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "USER_AGENT = \"cloud-solutions/data-to-ai-nb-v3\"\n",
        "\n",
        "PROJECT_ID = !gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "BQ_DATASET = \"ridership_lakehouse\"\n",
        "BUCKET_NAME = f\"{PROJECT_ID}-ridership-lakehouse\"\n",
        "LOCATION = \"us-central1\"\n",
        "BQ_CONNECTION_NAME = \"cloud-resources-connection\"\n",
        "\n",
        "print(PROJECT_ID)\n",
        "print(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "lEQa",
      "metadata": {
        "id": "lEQa"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery, storage\n",
        "from google.api_core.client_info import ClientInfo\n",
        "\n",
        "bigquery_client = bigquery.Client(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    client_info=ClientInfo(user_agent=USER_AGENT)\n",
        ")\n",
        "storage_client = storage.Client(\n",
        "    project=PROJECT_ID,\n",
        "    client_info=ClientInfo(user_agent=USER_AGENT)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the tables and load data"
      ],
      "metadata": {
        "id": "OWx9xx9aWpGu"
      },
      "id": "OWx9xx9aWpGu"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Xref",
      "metadata": {
        "id": "Xref",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5983ac7e-b80e-4291-d998-ffa6ac79549e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ea77634d590>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "bus_stops_uri = f\"gs://{BUCKET_NAME}/iceberg_data/bus_stations/\"\n",
        "bus_lines_uri = f\"gs://{BUCKET_NAME}/iceberg_data/bus_lines/\"\n",
        "ridership_uri = f\"gs://{BUCKET_NAME}/iceberg_data/ridership/\"\n",
        "\n",
        "bigquery_client.query(f\"DROP TABLE IF EXISTS {BQ_DATASET}.bus_stations;\").result()\n",
        "query = f\"\"\"\n",
        "CREATE TABLE {BQ_DATASET}.bus_stations\n",
        "(\n",
        "  bus_stop_id INTEGER,\n",
        "  address STRING,\n",
        "  school_zone BOOLEAN,\n",
        "  seating BOOLEAN,\n",
        "  latitude FLOAT64,\n",
        "  longtitude FLOAT64\n",
        ")\n",
        "WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{BQ_CONNECTION_NAME}`\n",
        "OPTIONS (\n",
        "  file_format = 'PARQUET',\n",
        "  table_format = 'ICEBERG',\n",
        "  storage_uri = '{bus_stops_uri}');\n",
        "\"\"\"\n",
        "bigquery_client.query(query).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "SFPL",
      "metadata": {
        "id": "SFPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1ab6fb-264e-434c-95de-1cf1128d09f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ea764d8b990>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "bigquery_client.query(\n",
        "    f'DROP TABLE IF EXISTS {BQ_DATASET}.bus_lines;'\n",
        ").result()\n",
        "_create_table_stmt = f\"\"\"\n",
        "    CREATE TABLE {BQ_DATASET}.bus_lines (\n",
        "        bus_line_id INTEGER,\n",
        "        bus_line STRING,\n",
        "        number_of_stops INTEGER,\n",
        "        stops ARRAY<INTEGER>,\n",
        "        frequency_minutes INTEGER\n",
        "    )\n",
        "    WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{BQ_CONNECTION_NAME}`\n",
        "    OPTIONS (\n",
        "        file_format = 'PARQUET',\n",
        "        table_format = 'ICEBERG',\n",
        "        storage_uri = '{bus_lines_uri}'\n",
        "    );\n",
        "\"\"\"\n",
        "bigquery_client.query(_create_table_stmt).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "BYtC",
      "metadata": {
        "id": "BYtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a40049f-0a11-40e5-d6e7-5a8afccf7e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ea72c854350>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "bigquery_client.query(\n",
        "    f'DROP TABLE IF EXISTS {BQ_DATASET}.ridership;'\n",
        ").result()\n",
        "_create_table_stmt = f\"\"\"\n",
        "    CREATE TABLE {BQ_DATASET}.ridership (\n",
        "        transit_timestamp TIMESTAMP,\n",
        "        station_id INTEGER,\n",
        "        ridership INTEGER\n",
        "    )\n",
        "    WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{BQ_CONNECTION_NAME}`\n",
        "    OPTIONS (\n",
        "        file_format = 'PARQUET',\n",
        "        table_format = 'ICEBERG',\n",
        "        storage_uri = '{ridership_uri}'\n",
        "    );\n",
        "\"\"\"\n",
        "bigquery_client.query(_create_table_stmt).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Kclp",
      "metadata": {
        "id": "Kclp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc093b4b-8a74-4e41-e5e3-f74cf50d8f5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoadJob<project=lakehouse-demo-1000, location=us-central1, id=6a96e8e1-7c43-4f3c-9005-a0528afc0ca6>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset_ref = bigquery_client.dataset(BQ_DATASET)\n",
        "table_ref = dataset_ref.table(\"bus_lines\")\n",
        "\n",
        "# BQ tables for Apache Iceberg do not support load with truncating, so we will truncate manually, and then load\n",
        "truncate = bigquery_client.query(f\"DELETE FROM {BQ_DATASET}.bus_lines WHERE TRUE\")\n",
        "truncate.result()\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        ")\n",
        "\n",
        "job = bigquery_client.load_table_from_uri(\n",
        "    f\"gs://{BUCKET_NAME}/mta_staging_data/bus_lines.json\",\n",
        "    table_ref,\n",
        "    job_config=job_config,\n",
        ")\n",
        "\n",
        "job.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "emfo",
      "metadata": {
        "id": "emfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c3ae35-3134-43cf-eabd-c91146aa06a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoadJob<project=lakehouse-demo-1000, location=us-central1, id=1f529f45-11d1-4644-9ce8-abd1990156b0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "table_ref = dataset_ref.table(\"bus_stations\")\n",
        "\n",
        "# BQ tables for Apache Iceberg do not support load with truncating, so we will truncate manually, and then load\n",
        "truncate = bigquery_client.query(f\"DELETE FROM {BQ_DATASET}.bus_stations WHERE TRUE\")\n",
        "truncate.result()\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,\n",
        ")\n",
        "\n",
        "job = bigquery_client.load_table_from_uri(\n",
        "    f\"gs://{BUCKET_NAME}/mta_staging_data/bus_stations.csv\",\n",
        "    table_ref,\n",
        "    job_config=job_config,\n",
        ")\n",
        "\n",
        "job.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Hstk",
      "metadata": {
        "id": "Hstk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18951878-eed2-4e9e-cf56-9350b66b6a92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoadJob<project=lakehouse-demo-1000, location=us-central1, id=7f3dd344-6687-4fcd-819c-289b51ed9594>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "table_ref = dataset_ref.table(\"ridership\")\n",
        "\n",
        "# BQ tables for Apache Iceberg do not support load with truncating, so we will truncate manually, and then load\n",
        "truncate = bigquery_client.query(f\"DELETE FROM {BQ_DATASET}.ridership WHERE TRUE\")\n",
        "truncate.result()\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,\n",
        ")\n",
        "\n",
        "job = bigquery_client.load_table_from_uri(\n",
        "    f\"gs://{BUCKET_NAME}/mta_staging_data/ridership/*.csv\",\n",
        "    table_ref,\n",
        "    job_config=job_config,\n",
        ")\n",
        "\n",
        "job.result()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nWHF",
      "metadata": {
        "marimo": {
          "config": {
            "hide_code": true
          }
        },
        "id": "nWHF"
      },
      "source": [
        "## Basic Analytics\n",
        "After loading the data to our open data lakehouse, we will demonstrate some basic analytics, but we will repeat the process with several different engines\n",
        "- BigQuery\n",
        "- Spark (serverless?)\n",
        "- Dataflow"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "lakehouse_part1_load_data.ipynb"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}